{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is a Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This tutorial is adapted from [Damir Cavar](http://damir.cavar.me/) and Callie Federer tutorial**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's imagine we have to make a decision about going for a workout or not. We have the following things to take into account:\n",
    "\n",
    "- #### Weather (Sunny or Rainy) ?\n",
    "- #### Time of Day (Morning or Evening) ?\n",
    "- #### Energy Level (Energized) ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Perceptron_Cartoon](perceptron_cartoon.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A perceptron is simple model that can help us solve such a problem given enough data. **The perceptron can be defined as an algorithm for supervised binary classification.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial Example: To Gym or Not To Gym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import *numpy* and define our *activation* function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def bactivation(z):\n",
    "    if z == 0.5:\n",
    "        return 1\n",
    "    else: return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we define our example data **input** $x$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = 0\n",
    "evening = 1\n",
    "energized = 1\n",
    "x = np.array([weather, evening, energized])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, we define the corresponding **weights** $w$, and **bias** $b$ of our perceptron $p$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.array([0.5, 0.5, 0])\n",
    "b = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our perceptron would compute $p$ as the **dot-product** $w \\cdot x$ and add the **bias** $b$ to it. Subsequently, the sigmoid function defined above will convert this $p$ value to the **activation value** $a$ of the unit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = w.dot(x) + b\n",
    "a = bactivation(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron Value (p): 0.5\n",
      "Activation Value of Perceptron (a): 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Perceptron Value (p):\", p)\n",
    "print(\"Activation Value of Perceptron (a):\", a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a viz with the different values here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logic Gates (AND, OR) with Perceptrons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task is to implement a simple **perceptron** to compute logical operations like AND, and OR.\n",
    "\n",
    "- Input: $x_1$ and $x_2$\n",
    "- Bias: $b = -1$ for AND; $b = 0$ for OR\n",
    "- Weights: $w = [1, 1]$\n",
    "\n",
    "with the following activation function:\n",
    "\n",
    "$$\n",
    "y = \\begin{cases}\n",
    "    \\ 0 & \\quad \\text{if } w \\cdot x + b \\leq 0\\\\\n",
    "    \\ 1 & \\quad \\text{if } w \\cdot x + b > 0\n",
    "  \\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can define this threshold function in Python as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(z):\n",
    "    if z > 0:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For AND we could implement a perceptron as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 AND 0: 0\n",
      "1 AND 0: 0\n",
      "0 AND 1: 0\n",
      "1 AND 1: 1\n"
     ]
    }
   ],
   "source": [
    "w = np.array([1, 1])\n",
    "b = -1\n",
    "x = np.array([0, 0])\n",
    "print(\"0 AND 0:\", activation(w.dot(x) + b))\n",
    "x = np.array([1, 0])\n",
    "print(\"1 AND 0:\", activation(w.dot(x) + b))\n",
    "x = np.array([0, 1])\n",
    "print(\"0 AND 1:\", activation(w.dot(x) + b))\n",
    "x = np.array([1, 1])\n",
    "print(\"1 AND 1:\", activation(w.dot(x) + b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For OR we could implement a perceptron as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 OR 0: 0\n",
      "1 OR 0: 1\n",
      "0 OR 1: 1\n",
      "1 OR 1: 1\n"
     ]
    }
   ],
   "source": [
    "w = np.array([1, 1])\n",
    "b = 0\n",
    "x = np.array([0, 0])\n",
    "print(\"0 OR 0:\", activation(w.dot(x) + b))\n",
    "x = np.array([1, 0])\n",
    "print(\"1 OR 0:\", activation(w.dot(x) + b))\n",
    "x = np.array([0, 1])\n",
    "print(\"0 OR 1:\", activation(w.dot(x) + b))\n",
    "x = np.array([1, 1])\n",
    "print(\"1 OR 1:\", activation(w.dot(x) + b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Famous XOR Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The power of neural units comes from combining them into larger networks. Minsky and Papert (1969): A single neural unit cannot compute the simple logical function XOR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this narrow definition of a perceptron, it seems not possible to implement an XOR logic perceptron. The restriction is that there is a threshold function that is binary and piecewise linear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As one student in my 2020 L645 class, Kazuki Yabe, points out, with a different activation function and a different weight vector, one unit can of course handle XOR. If we use the following activation function:\n",
    "\n",
    "$$\n",
    "y = \\begin{cases}\n",
    "    \\ 0 & \\quad \\text{if } w \\cdot x + b \\neq 0.5\\\\\n",
    "    \\ 1 & \\quad \\text{if } w \\cdot x + b = 0.5\n",
    "  \\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bactivation(z):\n",
    "    if z == 0.5:\n",
    "        return 1\n",
    "    else: return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we assume the weights to be set to 0.5 and the bias to 0, one unit can handle the XOR logic:\n",
    "\n",
    "- Input: $x_1$ and $x_2$\n",
    "- Bias: $b = 0$ for XOR\n",
    "- Weights: $w = [0.5, 0.5]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 OR 0: 0\n",
      "1 OR 0: 1\n",
      "0 OR 1: 1\n",
      "1 OR 1: 0\n"
     ]
    }
   ],
   "source": [
    "w = np.array([0.5, 0.5])\n",
    "b = 0\n",
    "x = np.array([0, 0])\n",
    "print(\"0 OR 0:\", bactivation(w.dot(x) + b))\n",
    "x = np.array([1, 0])\n",
    "print(\"1 OR 0:\", bactivation(w.dot(x) + b))\n",
    "x = np.array([0, 1])\n",
    "print(\"0 OR 1:\", bactivation(w.dot(x) + b))\n",
    "x = np.array([1, 1])\n",
    "print(\"1 OR 1:\", bactivation(w.dot(x) + b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This particular activation function is of course not differentiable, and it remains to be shown that the weights can be learned, but nevertheless, a single unit can be identified that solves the XOR problem.\n",
    "\n",
    "The difference between Minsky and Papert's (1969) definition of a perceptron and this unit is that - as Julia Hockenmaier pointed out - a perceptron is defined to have a decision function that would be binary and piecewise linear. This means that the unit that solves the XOR problem is not compatible with the definition of perceptron as in Minsky and Papert (1969) (p.c. Julia Hockenmaier)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (WIP) Training Perceptrons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up until this point, we have been solely performing inference with these models. How do we get the weights? In this section, we delve into how to train these perceptrons with data (Weight Estimation). **We will be classifying between apples and oranges!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fruit_label</th>\n",
       "      <th>fruit_name</th>\n",
       "      <th>mass</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>color_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>apple</td>\n",
       "      <td>140</td>\n",
       "      <td>7.3</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>orange</td>\n",
       "      <td>140</td>\n",
       "      <td>6.7</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>apple</td>\n",
       "      <td>152</td>\n",
       "      <td>7.6</td>\n",
       "      <td>7.3</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>orange</td>\n",
       "      <td>142</td>\n",
       "      <td>7.6</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>orange</td>\n",
       "      <td>144</td>\n",
       "      <td>6.8</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fruit_label fruit_name  mass  width  height  color_score\n",
       "0            0      apple   140    7.3     7.1         0.87\n",
       "1            1     orange   140    6.7     7.1         0.72\n",
       "2            0      apple   152    7.6     7.3         0.69\n",
       "3            1     orange   142    7.6     7.8         0.75\n",
       "4            1     orange   144    6.8     7.4         0.75"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "\n",
    "fruits = pd.read_table('apples_n_oranges.txt')\n",
    "fruits.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first define our activation function for our perceptron:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_fxn(x):\n",
    "    ''' an implementation of the step function'''\n",
    "    if summation > 0:\n",
    "        activation = 1   ### step function\n",
    "    else:\n",
    "        activation = 0 \n",
    "    return activation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MinMaxScaler(x):\n",
    "    ''' Transforms features by scaling each feature to range (0,1)'''\n",
    "    scaled_xs = [] \n",
    "    x_min = np.min(x)\n",
    "    x_max = np.max(x)\n",
    "    for v in x:\n",
    "        x_std = (v - x_min) / (x_max - x_min)\n",
    "        x_scaled = x_std * (1 - 0) + 0\n",
    "        scaled_xs.append(x_scaled)\n",
    "    return scaled_xs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(n_correct, n_total):\n",
    "    accuracy = n_correct / n_total\n",
    "    print('Accuracy is ' + str(100*accuracy) + '%')\n",
    "    return accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple :  19\n",
      "orange :  19\n"
     ]
    }
   ],
   "source": [
    "### \n",
    "unique_fruit_cat = fruits['fruit_name'].unique()\n",
    "for fruit in unique_fruit_cat:\n",
    "    print(fruit, \": \", len(fruits[fruits['fruit_name'] == fruit]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 8\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "training_data = fruits.sample(frac=0.8, replace=False)\n",
    "test_data = fruits.drop(training_data.index)\n",
    "print(len(training_data), len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['mass', 'width', 'height', 'color_score']\n",
    "train = fruits.sample(frac=0.8, random_state=200)\n",
    "test = fruits.drop(train.index)\n",
    "X_train, y_train = train[feature_names], train['fruit_label']\n",
    "X_test, y_test = test[feature_names], test['fruit_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = pd.DataFrame()\n",
    "X_test_scaled = pd.DataFrame()\n",
    "X_train_scaled['mass'] = MinMaxScaler(X_train['mass'])\n",
    "X_train_scaled['width'] = MinMaxScaler(X_train['width'])\n",
    "X_train_scaled['height'] = MinMaxScaler(X_train['height'])\n",
    "X_train_scaled['color_score'] = MinMaxScaler(X_train['color_score'])\n",
    "X_test_scaled['mass'] = MinMaxScaler(X_test['mass'])\n",
    "X_test_scaled['width'] = MinMaxScaler(X_test['width'])\n",
    "X_test_scaled['height'] = MinMaxScaler(X_test['height'])\n",
    "X_test_scaled['color_score'] = MinMaxScaler(X_test['color_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mass           0.054054\n",
       "width          0.310345\n",
       "height         0.192308\n",
       "color_score    0.368421\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001 ## how large of updates should we make at each step\n",
    "weights = [0.46, 1.22, 1.04, -0.23] \n",
    "epochs = 1000 ## number of times to iterate through all the training set examples and update the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m     weights \u001b[38;5;241m=\u001b[39m weights \u001b[38;5;241m+\u001b[39m d_weights\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch : \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(_))\n\u001b[0;32m---> 22\u001b[0m \u001b[43maccuracy\u001b[49m(n_correct, \u001b[38;5;28mlen\u001b[39m(X_train_scaled))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'accuracy' is not defined"
     ]
    }
   ],
   "source": [
    "for _ in range(epochs):\n",
    "    n_correct = 0 \n",
    "    for idx in range(len(X_train_scaled)):\n",
    "        ### select the training sample \n",
    "        X = X_train_scaled.iloc[idx]\n",
    "        Y = y_train.iloc[idx]\n",
    "        \n",
    "        ### forward pass (1) calculate the weighted sum over all the inputs\n",
    "        summation = sum(X*weights) \n",
    "        ### forward pass (2) calculate the activation function\n",
    "        activation = step_fxn(summation)\n",
    "\n",
    "        ### calculate the error \n",
    "        error = Y - activation\n",
    "        if (error==0):\n",
    "            n_correct +=1\n",
    "        ### backwards pass: calculate the update to the weights. w = w + learning_rate *error*X\n",
    "        d_weights = learning_rate * error* X\n",
    "        weights = weights + d_weights\n",
    "        \n",
    "    print('Epoch : ' + str(_))\n",
    "    accuracy(n_correct, len(X_train_scaled))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 37.5%\n"
     ]
    }
   ],
   "source": [
    "n_correct = 0 \n",
    "for idx in range(len(X_test_scaled)):\n",
    "    \n",
    "    ### select testing sample \n",
    "    X = X_test_scaled.iloc[idx]\n",
    "    Y = y_test.iloc[idx]\n",
    "\n",
    "    ### calculate the model output \n",
    "    summation = sum(X*weights)#+ bias\n",
    "    activation = step_fxn(summation)\n",
    "    \n",
    "    ### add one to number correct if they match \n",
    "    if(activation == Y):\n",
    "        n_correct += 1\n",
    "    \n",
    "accuracy = n_correct / len(X_test)\n",
    "print('Accuracy is ' + str(100*accuracy) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revisiting Minsky and Papert (1969): Tri-Perceptron XOR Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a proposed solution in [Goodfellow et al. (2016)](https://www.deeplearningbook.org/) for the XOR problem, using a network with two layers of ReLU-based units."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![XOR Network](XOR_Network.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This two layer and three perceptron network solves the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more deiscussion on this problem, consult:\n",
    "\n",
    "- [Wikipedia on the XOR problem](https://en.wikipedia.org/wiki/Perceptron)\n",
    "- [Solving XOR with a single Perceptron](https://medium.com/@lucaspereira0612/solving-xor-with-a-single-perceptron-34539f395182)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (WIP) Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essentially, the multi-layer perceptron is the solution to the **Famous XOR Problem** and addresses Minsky and Papert's concerns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sigmoid(Z):\n",
    "    ''' the sigmoid function'''\n",
    "    return 1/(1+np.exp(-Z))\n",
    "\n",
    "def dSigmoid(Z):\n",
    "    ''' the derivative of sigmoid function'''\n",
    "    s = 1/(1+np.exp(-Z))\n",
    "    dZ = s * (1-s)\n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = {\n",
    "'x1': 70, \n",
    "'x2': 16 ,\n",
    "'w1': 0.15,\n",
    "'w2': 0.20,\n",
    "'w3': 0.25,\n",
    "'w4': 0.30,\n",
    "'w5': 0.40,\n",
    "'w6': 0.45,\n",
    "'w7': 0.50,\n",
    "'w8': 0.55, \n",
    "'target1': 1.0,\n",
    "'target2': 0.0,\n",
    "'eta' : 0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"network.png\" width=\"350\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Forward pass\n",
    "\n",
    "Calculate the weighted sum and output for both hidden layers and both outputs. \n",
    "\n",
    "$net_{h1} = w_1 * x_1 + w_2 * x_2$\n",
    "\n",
    "$out_{h1} = $\n",
    "$\\frac{1}{1 + e^{-net_{h1}}}$\n",
    "\n",
    "$net_{h2} = w_3 * x_1 + w_4 * x_2$\n",
    "\n",
    "$out_{h2} = $\n",
    "$\\frac{1}{1 + e^{-net_{h2}}}$\n",
    "\n",
    "$net_{o1} = w_5 * out_{h1} + w_6 * out_{h2}$\n",
    "\n",
    "$out_{o1} = $\n",
    "$\\frac{1}{1 + e^{-net_{o1}}}$\n",
    "\n",
    "$net_{o2} = w_7 * out_{h1} + w_8 * out_{h2}$\n",
    "\n",
    "$out_{o2} = $\n",
    "$\\frac{1}{1 + e^{-net_{o2}}}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(nn):\n",
    "    nn['net_h1'] = nn['w1'] * nn['x1'] + nn['w2'] * nn['x2']\n",
    "    nn['net_h2'] = nn['w3'] * nn['x1'] + nn['w4'] * nn['x2']\n",
    "    nn['out_h1'] = Sigmoid(nn['net_h1'])\n",
    "    nn['out_h2'] = Sigmoid(nn['net_h2'])\n",
    "    nn['net_o1'] = nn['w5'] * nn['out_h1']  + nn['w6'] * nn['out_h2']\n",
    "    nn['net_o2'] = nn['w7'] * nn['out_h1']  + nn['w8'] * nn['out_h2']\n",
    "    nn['out_o1'] = Sigmoid(nn['net_o1'])\n",
    "    nn['out_o2'] = Sigmoid(nn['net_o2']) \n",
    "    return nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x1': 70,\n",
       " 'x2': 16,\n",
       " 'w1': 0.15,\n",
       " 'w2': 0.2,\n",
       " 'w3': 0.25,\n",
       " 'w4': 0.3,\n",
       " 'w5': 0.4,\n",
       " 'w6': 0.45,\n",
       " 'w7': 0.5,\n",
       " 'w8': 0.55,\n",
       " 'target1': 1.0,\n",
       " 'target2': 0.0,\n",
       " 'eta': 0.1,\n",
       " 'net_h1': 13.7,\n",
       " 'net_h2': 22.3,\n",
       " 'out_h1': 0.9999988775548947,\n",
       " 'out_h2': 0.9999999997933511,\n",
       " 'net_o1': 0.849999550928966,\n",
       " 'net_o2': 1.0499994386637905,\n",
       " 'out_o1': 0.7005670482710666,\n",
       " 'out_o2': 0.7407747913901797}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward(nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error calculation \n",
    "\n",
    "The squared error function\n",
    "\n",
    "$E_{total} = \\sum\\frac{1}{2}(target - output)^2$\n",
    "\n",
    "$E_{o1} = \\frac{1}{2}(target_{o1} - output_{o1})^2$\n",
    "\n",
    "$E_{o2} = \\frac{1}{2}(target_{o2} - output_{o2})^2$\n",
    "\n",
    "$E_{total} = E_{o1} + E_{o2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_error(nn):\n",
    "    nn['err1'] = (1/2) * (nn['target1'] - nn['out_o1'])**2\n",
    "    nn['err2'] = (1/2) * (nn['target2'] - nn['out_o2'])**2\n",
    "    nn['total_error'] = nn['err1'] + nn['err2']\n",
    "    return nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_error(nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The backwards pass\n",
    "\n",
    "output weight updates: \n",
    "\n",
    "$\\frac{\\partial E_{total}}{\\partial w_5} = \\frac{\\partial E_{total}}{\\partial out_{o1}} * \\frac{\\partial out_{o1}}{\\partial net_{o1}} * \\frac{\\partial net_{o1}}{\\partial w_5}$\n",
    "\n",
    "$\\frac{\\partial E_{total}}{\\partial w_6} = \\frac{\\partial E_{total}}{\\partial out_{o1}} * \\frac{\\partial out_{o1}}{\\partial net_{o1}} * \\frac{\\partial net_{o1}}{\\partial w_6}$\n",
    "\n",
    "$\\frac{\\partial E_{total}}{\\partial w_7} = \\frac{\\partial E_{total}}{\\partial out_{o2}} * \\frac{\\partial out_{o2}}{\\partial net_{o2}} * \\frac{\\partial net_{o2}}{\\partial w_7}$\n",
    "\n",
    "$\\frac{\\partial E_{total}}{\\partial w_8} = \\frac{\\partial E_{total}}{\\partial out_{o2}} * \\frac{\\partial out_{o2}}{\\partial net_{o2}} * \\frac{\\partial net_{o2}}{\\partial w_8}$\n",
    "\n",
    "\n",
    "hidden weight updates: \n",
    "\n",
    "$\\frac{\\partial E_{total}}{\\partial w_1} = \\frac{\\partial E_{total}}{\\partial out_{h1}} * \\frac{\\partial out_{h1}}{\\partial net_{h1}} * \\frac{\\partial net_{h1}}{\\partial w_1}$\n",
    "\n",
    "$\\frac{\\partial E_{total}}{\\partial w_2} = \\frac{\\partial E_{total}}{\\partial out_{h1}} * \\frac{\\partial out_{h1}}{\\partial net_{h1}} * \\frac{\\partial net_{h1}}{\\partial w_2}$\n",
    "\n",
    "$\\frac{\\partial E_{total}}{\\partial w_3} = \\frac{\\partial E_{total}}{\\partial out_{h2}} * \\frac{\\partial out_{h2}}{\\partial net_{h2}} * \\frac{\\partial net_{h2}}{\\partial w_3}$\n",
    "\n",
    "$\\frac{\\partial E_{total}}{\\partial w_4} = \\frac{\\partial E_{total}}{\\partial out_{h2}} * \\frac{\\partial out_{h2}}{\\partial net_{h2}} * \\frac{\\partial net_{h2}}{\\partial w_4}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(nn):\n",
    "    ############ output weights \n",
    "    \n",
    "    ### w5 \n",
    "    nn['dErr_outo1'] = -(nn['target1'] - nn['out_o1'])\n",
    "    nn['douto1_neto1'] = dSigmoid(nn['out_o1'])\n",
    "    nn['dneto1_w5'] = nn['out_h1']\n",
    "    w5 = nn['w5'] - nn['eta'] * nn['dErr_outo1'] * nn['douto1_neto1'] * nn['dneto1_w5']\n",
    "    \n",
    "    ### w6\n",
    "    nn['dneto1_w6'] = nn['out_h2']\n",
    "    w6 = nn['w6'] - nn['eta'] * nn['dErr_outo1'] * nn['douto1_neto1'] * nn['dneto1_w6']\n",
    "\n",
    "    \n",
    "    ### w7 \n",
    "    nn['dErr_outo2'] = -(nn['target2'] - nn['out_o2'])\n",
    "    nn['douto2_neto2'] = dSigmoid(nn['out_o2'])\n",
    "    nn['dneto2_w7'] = nn['out_h1']\n",
    "    w7 = nn['w7'] - nn['eta'] * nn['dErr_outo2'] * nn['douto2_neto2'] * nn['dneto2_w7']\n",
    "    \n",
    "    ### w8\n",
    "    nn['dneto2_w8'] = nn['out_h2']\n",
    "    w8 = nn['w8'] - nn['eta'] * nn['dErr_outo2'] * nn['douto2_neto2'] * nn['dneto2_w8']\n",
    "    \n",
    "    ############ hidden weights \n",
    "    \n",
    "    ### w1 \n",
    "    nn['dErr_neto1'] = nn['dErr_outo1'] * nn['douto1_neto1']\n",
    "    nn['dneto1_outh1'] = nn['w5']\n",
    "    nn['dErr1_outh1'] = nn['dErr_neto1'] * nn['dneto1_outh1']\n",
    "    nn['dErr_neto2'] = nn['dErr_outo2'] * nn['douto2_neto2']\n",
    "    nn['dneto2_outh1'] = nn['w7']\n",
    "    nn['dErr2_outh1'] = nn['dErr_neto2'] * nn['dneto2_outh1']\n",
    "    nn['dErr_outh1'] = nn['dErr1_outh1'] + nn['dErr2_outh1']\n",
    "    nn['douth1_neth1'] = dSigmoid(nn['out_h1'])\n",
    "    nn['dneth1_w1'] = nn['x1']\n",
    "    w1 = nn['w1'] - nn['eta'] * nn['dErr_outh1'] * nn['douth1_neth1'] * nn['dneth1_w1']\n",
    "    \n",
    "    ### w2\n",
    "    nn['dneth1_w2'] = nn['x2']\n",
    "    w2 = nn['w2'] - nn['eta'] * nn['dErr_outh1'] * nn['douth1_neth1'] * nn['dneth1_w2']\n",
    "    \n",
    "    ### w3\n",
    "    nn['dneto1_outh2'] = nn['w6']\n",
    "    nn['dErr1_outh2'] = nn['dErr_neto1'] * nn['dneto1_outh2']\n",
    "    nn['dneto2_outh2'] = nn['w8'] \n",
    "    nn['dErr2_outh2'] = nn['dErr_neto2'] * nn['dneto2_outh2']\n",
    "    nn['dErr_outh2'] = nn['dErr1_outh2'] + nn['dErr2_outh2']\n",
    "    nn['douth2_neth2'] = dSigmoid(nn['out_h2'])\n",
    "    nn['dneth2_w3'] = nn['x1']\n",
    "    w3 = nn['w3'] - nn['eta'] * nn['dErr_outh2'] * nn['douth2_neth2'] * nn['dneth2_w3']\n",
    "    \n",
    "    ### w4\n",
    "    nn['dneth2_w4'] = nn['x2']\n",
    "    w4 = nn['w4'] - nn['eta'] * nn['dErr_outh2'] * nn['douth2_neth2'] * nn['dneth2_w4']\n",
    "    \n",
    "    ### update all weights simultaneously\n",
    "    nn['w1'] = w1\n",
    "    nn['w2'] = w2\n",
    "    nn['w3'] = w3\n",
    "    nn['w4'] = w4\n",
    "    nn['w5'] = w5\n",
    "    nn['w6'] = w6\n",
    "    nn['w7'] = w7\n",
    "    nn['w8'] = w8\n",
    "\n",
    "    return nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x1': 70,\n",
       " 'x2': 16,\n",
       " 'w1': 0.07510107754711555,\n",
       " 'w2': 0.18288024629648356,\n",
       " 'w3': 0.16852474274223866,\n",
       " 'w4': 0.2813770840553688,\n",
       " 'w5': 0.4066375399108027,\n",
       " 'w6': 0.45663754735971357,\n",
       " 'w7': 0.48380575740490334,\n",
       " 'w8': 0.5338057392310812,\n",
       " 'target1': 1.0,\n",
       " 'target2': 0.0,\n",
       " 'eta': 0.1,\n",
       " 'net_h1': 13.7,\n",
       " 'net_h2': 22.3,\n",
       " 'out_h1': 0.9999988775548947,\n",
       " 'out_h2': 0.9999999997933511,\n",
       " 'net_o1': 0.849999550928966,\n",
       " 'net_o2': 1.0499994386637905,\n",
       " 'out_o1': 0.7005670482710666,\n",
       " 'out_o2': 0.7407747913901797,\n",
       " 'dErr_outo1': -0.29943295172893336,\n",
       " 'douto1_neto1': 0.22167057175103325,\n",
       " 'dneto1_w5': 0.9999988775548947,\n",
       " 'dneto1_w6': 0.9999999997933511,\n",
       " 'dErr_outo2': 0.7407747913901797,\n",
       " 'douto2_neto2': 0.2186124711651475,\n",
       " 'dneto2_w7': 0.9999988775548947,\n",
       " 'dneto2_w8': 0.9999999997933511,\n",
       " 'dErr_neto1': -0.06637547361085219,\n",
       " 'dneto1_outh1': 0.4,\n",
       " 'dErr1_outh1': -0.02655018944434088,\n",
       " 'dErr_neto2': 0.16194260772265381,\n",
       " 'dneto2_outh1': 0.5,\n",
       " 'dErr2_outh1': 0.08097130386132691,\n",
       " 'dErr_outh1': 0.05442111441698603,\n",
       " 'douth1_neth1': 0.19661203522429374,\n",
       " 'dneth1_w1': 70,\n",
       " 'dneth1_w2': 16,\n",
       " 'dneto1_outh2': 0.45,\n",
       " 'dErr1_outh2': -0.029868963124883487,\n",
       " 'dneto2_outh2': 0.55,\n",
       " 'dErr2_outh2': 0.08906843424745961,\n",
       " 'dErr_outh2': 0.05919947112257612,\n",
       " 'douth2_neth2': 0.1966119332602575,\n",
       " 'dneth2_w3': 70,\n",
       " 'dneth2_w4': 16}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backward(nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_network(nn, niters = 10):\n",
    "    for i in range(niters):\n",
    "        nn = forward(nn)\n",
    "        print('output1: ' + str(nn['out_o1']) + ' target1: ' + str(nn['target1']))\n",
    "        print('output2: ' + str(nn['out_o2']) + ' target2: ' + str(nn['target2']))\n",
    "        nn = calc_error(nn)\n",
    "        print('Error: ' + str(nn['total_error']))\n",
    "\n",
    "        nn = backward(nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output1: 0.703320758742449 target1: 1.0\n",
      "output2: 0.7344807324321174 target2: 0.0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'calc_error' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrun_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mniters\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[38], line 6\u001b[0m, in \u001b[0;36mrun_network\u001b[0;34m(nn, niters)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput1: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(nn[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout_o1\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m target1: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(nn[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget1\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput2: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(nn[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout_o2\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m target2: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(nn[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget2\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[0;32m----> 6\u001b[0m nn \u001b[38;5;241m=\u001b[39m \u001b[43mcalc_error\u001b[49m(nn)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(nn[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_error\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[1;32m      9\u001b[0m nn \u001b[38;5;241m=\u001b[39m backward(nn)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'calc_error' is not defined"
     ]
    }
   ],
   "source": [
    "run_network(nn, niters = 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (WIP) Adaptive Optimization with MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment: Reproducing Rosenblatt's NYT Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Times_July_13_Rosenblatt_Perceptron](Times_July_13_Rosenblatt_Perceptron.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
